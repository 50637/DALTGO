{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stellargraph.mapper import GraphSAGELinkGenerator\n",
    "from stellargraph.layer import GraphSAGE, link_classification\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from stellargraph import globalvar, IndexedArray\n",
    "import pandas as pd\n",
    "from stellargraph import StellarGraph\n",
    "import pickle\n",
    "#build the GO graph\n",
    "source = []\n",
    "target = []\n",
    "weight = []\n",
    "with open(\"go-terms.edgelist\", \"r\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        source.append(line.split()[0])\n",
    "        target.append(line.split()[1])\n",
    "edges = pd.DataFrame(\n",
    "            {\"source\": source, \"target\": target}\n",
    "        )\n",
    "Gs = StellarGraph(edges=edges)\n",
    "\n",
    "dic=dict(Gs.node_degrees())\n",
    "with open('go_id_dict', 'rb') as f:\n",
    "    my_object = pickle.load(f)\n",
    "new_dict={}\n",
    "for c in my_object:\n",
    "    new_dict[my_object[c]]=c[3:]\n",
    "import csv\n",
    "def read_tab_file(file_path):\n",
    "    data = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            key = row[0]\n",
    "            values = row[1:]\n",
    "            data[key] = values\n",
    "    return data\n",
    "#get IC value of every GO term\n",
    "file_path = 'ic2.ext.tab'\n",
    "result = read_tab_file(file_path)\n",
    "dict={}\n",
    "for c in new_dict:\n",
    "    try :\n",
    "        dict[c] = float(result[new_dict[c]][0])\n",
    "    except:\n",
    "        dict[c] =0\n",
    "\n",
    "source = []\n",
    "target = []\n",
    "weight = []\n",
    "with open(\"go-terms.edgelist\", \"r\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        source.append(line.split()[0])\n",
    "        target.append(line.split()[1])\n",
    "        s=line.split()[0]\n",
    "        t=line.split()[1]\n",
    "        wei = dict[int(s)]*math.sqrt(dic[s])+dict[int(t)]*math.sqrt(dic[t])\n",
    "        wei = wei/2\n",
    "        weight.append(wei)\n",
    "edges = pd.DataFrame(\n",
    "            {\"source\": source, \"target\": target,\"weight\": weight}\n",
    "        )\n",
    "import csv\n",
    "index=[]\n",
    "feature_array = []\n",
    "with open('emb64.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        index.append(row[0])\n",
    "        feature_array.append(row[1:])\n",
    "\n",
    "feature_array=np.array(feature_array)\n",
    "feature_array = feature_array.astype(float)\n",
    "# As a IndexedArray (no column names):\n",
    "nodes = IndexedArray(feature_array, index=index)\n",
    "G = StellarGraph(nodes, edges)\n",
    "nodes = list(G.nodes())\n",
    "# print(nodes)\n",
    "number_of_walks = 10\n",
    "length = 10\n",
    "unsupervised_samples = UnsupervisedSampler(G, nodes=nodes, length=length, number_of_walks=number_of_walks)\n",
    "batch_size = 100\n",
    "epochs = 5\n",
    "num_samples = [5, 10]#num_samples [0] indicates the number of samples from the first-layer neighbors, and num_samples [1] indicates the number of samples from the second-layer neighbors.\n",
    "generator = GraphSAGELinkGenerator(G, batch_size, num_samples,weighted=True)\n",
    "train_gen = generator.flow(unsupervised_samples)\n",
    "layer_sizes = [128, 128]\n",
    "graphsage = GraphSAGE(layer_sizes=layer_sizes, generator=generator, bias=True, dropout=0.01, normalize=\"l2\")\n",
    "# Build the model and expose input and output sockets of graphsage, for node pair inputs:\n",
    "x_inp, x_out = graphsage.in_out_tensors()\n",
    "prediction = link_classification(\n",
    "    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\")(x_out)\n",
    "model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "# print(model.summary())\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=[keras.metrics.binary_accuracy],\n",
    ")\n",
    "print(model.summary())\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=False,\n",
    "    workers=4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "x_inp_src=x_inp[0::2]\n",
    "x_out_src = x_out[0]\n",
    "embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
    "# print(embedding_model.summary())\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator\n",
    "list = G.nodes()\n",
    "dict={}\n",
    "for c in list:\n",
    "    node_gen = GraphSAGENodeGenerator(G, batch_size, num_samples).flow([c])\n",
    "    for batch in node_gen:\n",
    "        node_embeddings = embedding_model.predict([[batch[0][0], batch[0][1], batch[0][2]]], workers=4, verbose=1)\n",
    "        dict[c]=node_embeddings\n",
    "    # print(batch[0][1].shape)\n",
    "# print(dict)\n",
    "#get vector of every GO term\n",
    "import pickle\n",
    "with open('dict_data128.pkl', 'wb') as file:\n",
    "    pickle.dump(dict, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
